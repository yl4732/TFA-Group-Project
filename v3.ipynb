{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yl4732/TFA-Group-Project/blob/main/v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32f8ca24",
      "metadata": {
        "id": "32f8ca24"
      },
      "source": [
        "# Understanding Hired Rides in NYC\n",
        "\n",
        "_[Project prompt](https://docs.google.com/document/d/1tGcX2qzS2GoaN5zFeD5DVJxqDmoQdmMs7QncZwFCEqU/edit#)_\n",
        "\n",
        "_This scaffolding notebook may be used to help setup your final project. It's totally optional whether you make use of this or not._\n",
        "\n",
        "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
        "\n",
        "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
        "\n",
        "_All code should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25627e8d",
      "metadata": {
        "id": "25627e8d"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
        "\n",
        "* Code clarity: make sure the code conforms to:\n",
        "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
        "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
        "    * [ ] Break each task down into logical functions\n",
        "* The following files are submitted for the project (see the project's GDoc for more details):\n",
        "    * [ ] `README.md`\n",
        "    * [ ] `requirements.txt`\n",
        "    * [ ] `.gitignore`\n",
        "    * [ ] `schema.sql`\n",
        "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
        "    * [x] Jupyter Notebook containing the project (this file!)\n",
        "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f75fd94",
      "metadata": {
        "id": "2f75fd94"
      },
      "source": [
        "## Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandasql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt_92lbXWZ17",
        "outputId": "1adb412d-7ad9-4ff3-c97f-bc7e9dd17c39"
      },
      "id": "Mt_92lbXWZ17",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandasql\n",
            "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.3.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.4.36)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (1.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->pandasql) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->pandasql) (4.2.0)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26784 sha256=0f2a5f3bd02eac68a5b52bb1d75652c4bafb95384c4a354f6a40ba16224a4533\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/4b/ec/41f4e116c8053c3654e2c2a47c62b4fca34cc67ef7b55deb7f\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66dcde05",
      "metadata": {
        "id": "66dcde05"
      },
      "outputs": [],
      "source": [
        "# all import statements needed for the project, for example:\n",
        "\n",
        "import math\n",
        "import bs4\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import requests\n",
        "import sqlalchemy as db\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIu4l04bXUAi",
        "outputId": "e20cc3c3-5887-447d-da26-f9372ef9e52f"
      },
      "id": "LIu4l04bXUAi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"pandasql\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b622a58",
      "metadata": {
        "id": "8b622a58"
      },
      "outputs": [],
      "source": [
        "# any general notebook setup, like log formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f1242c4",
      "metadata": {
        "id": "3f1242c4"
      },
      "outputs": [],
      "source": [
        "# any constants you might need, for example:\n",
        "\n",
        "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
        "# add other constants to refer to any local data, e.g. uber & weather\n",
        "UBER_CSV = \"uber_rides_sample.csv\"\n",
        "\n",
        "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
        "\n",
        "DATABASE_URL = \"sqlite:///project.db\"\n",
        "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
        "QUERY_DIRECTORY = \"queries\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ad10ea",
      "metadata": {
        "id": "26ad10ea"
      },
      "source": [
        "## Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf38168",
      "metadata": {
        "id": "ecf38168"
      },
      "source": [
        "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
        "\n",
        "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library\n",
        "* [ ] Write at least one unit test that tests this distance calculation function. \n",
        "* Taxi data:\n",
        "    * [ ] Use `requests`, BeautifulSoup (`bs4`), and `pandas` to programmatically download the required CSV files & load into memory.\n",
        "    * [ ] Clean the data, including:\n",
        "        * Remove unnecessary columns\n",
        "        * Remove invalid data points (take a moment to consider what's invalid)\n",
        "        * Normalize column names\n",
        "        * Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
        "    * [ ] Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
        "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
        "* Uber data:\n",
        "    * [ ] Download the data manually in the link provided in the project doc.\n",
        "    * [ ] Load the data from your local computer (using `pandas`), then clean the data, including: \n",
        "        * Remove unnecessary columns\n",
        "        * Remove invalid data points (take a moment to consider what's invalid)\n",
        "        * Normalize column names\n",
        "        * Remove trips that start and/or end outside the designated [coordinate box]\n",
        "* Using the function that calculates the distance between two coordinates in kilometers, add a column to each `pandas` DataFrame of data that calculates the distance between pickup and dropoff locations for each trip.\n",
        "* Weather data:\n",
        "    * [ ] Download the data manually in the link provided in the project doc.\n",
        "    * [ ] Load the data from your local computer (using `pandas`), then clean the data, including: \n",
        "        * Remove unnecessary columns\n",
        "        * Remove invalid data points (take a moment to consider what's invalid)\n",
        "        * Normalize column names\n",
        "        * Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
        "        * You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what you’re doing so we can follow along. \n",
        "* Take a look at the lecture notes from the `pandas` lecture for hints on helpful functionality"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32074561",
      "metadata": {
        "id": "32074561"
      },
      "source": [
        "### Calculating distance\n",
        "_Write some prose that tells the reader what you're about to do here._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cbbe6cc",
      "metadata": {
        "id": "4cbbe6cc"
      },
      "outputs": [],
      "source": [
        "def calculate_distance(from_coord, to_coord):\n",
        "  lat1, lon1 = from_coord\n",
        "  lat2, lon2 = to_coord\n",
        "  radius = 6371 # km\n",
        "\n",
        "  dlat = math.radians(lat2-lat1)\n",
        "  dlon = math.radians(lon2-lon1)\n",
        "  a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
        "  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
        "  d = radius * c\n",
        "  return d\n",
        "#calculate_distance((40.776440\t, -73.959862), (40.767906, -73.962837))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee0343a",
      "metadata": {
        "id": "bee0343a"
      },
      "outputs": [],
      "source": [
        "def test_calculate_distance():\n",
        "  assert calculate_distance((40.560445, -74.242330), (40.908524, -73.717047))==58.795089791900814"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6abf52",
      "metadata": {
        "id": "6d6abf52"
      },
      "outputs": [],
      "source": [
        "from typing import AnyStr\n",
        "def add_distance_column(dataframe):\n",
        "  coordinate_distance=[]\n",
        "  for index, row in dataframe.iterrows():\n",
        "    from_coord=(row['pickup_latitude'],row['pickup_longitude'])\n",
        "    to_coord=(row['dropoff_latitude'],row['dropoff_longitude'])\n",
        "    coordinate_distance.append(calculate_distance(from_coord,to_coord))  \n",
        "  dataframe= pd.concat([dataframe,pd.DataFrame(coordinate_distance,columns=['coordinate_distance'])], axis=1)\n",
        "  print(len(coordinate_distance))\n",
        "  return dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93daa717",
      "metadata": {
        "id": "93daa717"
      },
      "source": [
        "### Processing Taxi Data\n",
        "\n",
        "_Write some prose that tells the reader what you're about to do here._"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qFiiwsbcvsxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b880208-efea-4798-ebe4-1abed46dc57f"
      },
      "id": "qFiiwsbcvsxl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd0d198",
      "metadata": {
        "id": "cbd0d198"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "def find_taxi_csv_urls(TAXI_URL):\n",
        "    response = requests.get(TAXI_URL)\n",
        "    if not response.status_code == 200:\n",
        "        return None\n",
        "    result_page = BeautifulSoup(response.content,'lxml')\n",
        "    taxi_urls = list()\n",
        "    all_taxi_urls=list()\n",
        "\n",
        "    for year in result_page.find_all('div',{\"id\":re.compile('faq.*')}):\n",
        "\n",
        "        for month in year.find_all('a', {\"title\": 'Yellow Taxi Trip Records'}):\n",
        "            taxi_urls.append(month.get('href'))\n",
        "\n",
        "    for i in taxi_urls:\n",
        "      if i[-11:-4]>=\"2009-01\" and i[-11:-4]<=\"2015-06\":\n",
        "        all_taxi_urls.append(i)   \n",
        "    return all_taxi_urls\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_and_clean_month_taxi_data(url):\n",
        "    df = pd.read_csv(url)\n",
        "    df.columns = df.columns.str.lower()\n",
        "    words = ['time', 'lon', 'lat', 'tip', 'distance','total']\n",
        "    df_new = pd.DataFrame()\n",
        "    for i in words:\n",
        "      col=df.loc[:,df.columns.str.contains(i)]\n",
        "      df_new=pd.concat([df_new, col], axis=1)\n",
        "    mapping = {df_new.columns[0]:'pickup_datetime', \n",
        "           df_new.columns[1]: 'dropoff_datetime', \n",
        "           df_new.columns[2]: 'pickup_longitude', \n",
        "           df_new.columns[3]: 'dropoff_longitude',\n",
        "           df_new.columns[4]: 'pickup_latitude',\n",
        "           df_new.columns[5]: 'dropoff_latitude',\n",
        "           df_new.columns[6]: 'tip',\n",
        "           df_new.columns[7]: 'distance',\n",
        "           df_new.columns[8]: 'total_amount'}\n",
        "    yellow_taxi = df_new.rename(columns=mapping)\n",
        "    yellow_taxi_clean = yellow_taxi.dropna()\n",
        "    filter = yellow_taxi_clean.loc[yellow_taxi_clean.pickup_longitude.between(-74.242330,-73.717047) & yellow_taxi_clean.dropoff_longitude.between(-74.242330,-73.717047) \n",
        "    & yellow_taxi_clean.pickup_latitude.between(40.560445,40.908524)& yellow_taxi_clean.dropoff_latitude.between(40.560445,40.908524)]\n",
        "    sample= filter.sample(n=2564)\n",
        "    sample.reset_index(drop=True, inplace=True)\n",
        "    return sample\n",
        "\n",
        "    \n",
        "\n",
        "def get_and_clean_taxi_data():\n",
        "    all_taxi_dataframes = []\n",
        "    \n",
        "    all_csv_urls = find_taxi_csv_urls(TAXI_URL)\n",
        "    for csv_url in all_csv_urls:\n",
        "        # maybe: first try to see if you've downloaded this exact\n",
        "        # file already and saved it before trying again\n",
        "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
        "        re=add_distance_column(dataframe)\n",
        "        # maybe: if the file hasn't been saved, save it so you can\n",
        "        # avoid re-downloading it if you re-run the function\n",
        "        \n",
        "        #save monthly cleaned data into drive\n",
        "        from pathlib import Path\n",
        "        #get the month of the cleaned data\n",
        "        month = csv_url[-11:]\n",
        "        #create path for the month\n",
        "        filepath = Path(f'/content/drive/MyDrive/TFA_test/monthly_data/{month}') \n",
        "        #check whether there is an existing parent path:\n",
        "        #if there is, save file under the path; if there isn't, create a new parent path\n",
        "        filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "        re.to_csv(filepath, index=False)  \n",
        "        all_taxi_dataframes.append(re)\n",
        "\n",
        "    # create one gigantic dataframe with data from every month needed\n",
        "    taxi_data = pd.concat(all_taxi_dataframes)\n",
        "    \n",
        "    #save the aggregate cleaned data into drive\n",
        "    filepath = Path('/content/drive/MyDrive/TFA_test/taxi.csv')  \n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "    taxi_data.to_csv(filepath, index=False)  \n",
        "    return taxi_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=pd.read_csv('/content/drive/MyDrive/TFA_test/monthly_data/2015-01.csv')\n",
        "print(a)"
      ],
      "metadata": {
        "id": "dV-SEbI60gGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6304ea-ec44-445a-e4dc-cb6314b7fc7e"
      },
      "id": "dV-SEbI60gGe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          pickup_datetime     dropoff_datetime  pickup_longitude  \\\n",
            "0     2015-01-04 11:45:30  2015-01-04 11:53:14        -73.967659   \n",
            "1     2015-01-11 05:40:34  2015-01-11 06:04:40        -73.984016   \n",
            "2     2015-01-15 14:53:55  2015-01-15 15:09:55        -73.947823   \n",
            "3     2015-01-09 23:37:38  2015-01-09 23:51:00        -73.989609   \n",
            "4     2015-01-13 20:16:03  2015-01-13 20:32:07        -73.986198   \n",
            "...                   ...                  ...               ...   \n",
            "2559  2015-01-03 20:35:33  2015-01-03 20:37:43        -73.982002   \n",
            "2560  2015-01-24 23:57:18  2015-01-25 00:13:38        -74.003342   \n",
            "2561  2015-01-18 16:49:45  2015-01-18 17:02:06        -73.974670   \n",
            "2562  2015-01-08 23:03:43  2015-01-08 23:34:35        -73.983040   \n",
            "2563  2015-01-04 15:57:16  2015-01-04 16:01:35        -73.985565   \n",
            "\n",
            "      dropoff_longitude  pickup_latitude  dropoff_latitude    tip  distance  \\\n",
            "0            -73.965454        40.756008         40.766533   1.55      1.00   \n",
            "1            -73.789909        40.743591         40.646961   8.00     16.60   \n",
            "2            -73.971748        40.770859         40.765907   1.00      1.80   \n",
            "3            -73.952293        40.762680         40.769730   3.12      2.94   \n",
            "4            -73.982346        40.726257         40.756344   2.85      2.70   \n",
            "...                 ...              ...               ...    ...       ...   \n",
            "2559         -73.981346        40.767986         40.767494   1.00      0.00   \n",
            "2560         -73.978668        40.733135         40.744980   0.00      2.40   \n",
            "2561         -73.981972        40.756886         40.765900   1.00      1.30   \n",
            "2562         -73.879776        40.767727         40.701225  10.40     11.10   \n",
            "2563         -73.978149        40.747116         40.752449   1.15      0.70   \n",
            "\n",
            "      total_amount  coordinate_distance  \n",
            "0             9.35             1.184941  \n",
            "1            66.13            19.576706  \n",
            "2            13.30             2.088758  \n",
            "3            16.42             3.238871  \n",
            "4            17.15             3.361178  \n",
            "...            ...                  ...  \n",
            "2559          5.80             0.077765  \n",
            "2560         13.30             2.460882  \n",
            "2561         10.80             1.175928  \n",
            "2562         52.03            11.418538  \n",
            "2563          6.95             0.861324  \n",
            "\n",
            "[2564 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[\"pickup_datetime\"] = pd.to_datetime(a[\"pickup_datetime\"])\n",
        "a[\"dayofweek\"] = a[\"pickup_datetime\"].dt.dayofweek\n",
        "a[\"year\"] = a[\"pickup_datetime\"].dt.year\n",
        "a[\"month\"] = a[\"pickup_datetime\"].dt.month\n",
        "a[\"day\"] = a[\"pickup_datetime\"].dt.day\n",
        "a[\"hour\"] = a[\"pickup_datetime\"].dt.hour\n",
        "a=a.drop(columns=['distance'])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "fsM5n4eTtD7c",
        "outputId": "791241d4-7a97-47b7-af16-4a98384e8f05"
      },
      "id": "fsM5n4eTtD7c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         pickup_datetime     dropoff_datetime  pickup_longitude  \\\n",
              "0    2015-01-04 11:45:30  2015-01-04 11:53:14        -73.967659   \n",
              "1    2015-01-11 05:40:34  2015-01-11 06:04:40        -73.984016   \n",
              "2    2015-01-15 14:53:55  2015-01-15 15:09:55        -73.947823   \n",
              "3    2015-01-09 23:37:38  2015-01-09 23:51:00        -73.989609   \n",
              "4    2015-01-13 20:16:03  2015-01-13 20:32:07        -73.986198   \n",
              "...                  ...                  ...               ...   \n",
              "2559 2015-01-03 20:35:33  2015-01-03 20:37:43        -73.982002   \n",
              "2560 2015-01-24 23:57:18  2015-01-25 00:13:38        -74.003342   \n",
              "2561 2015-01-18 16:49:45  2015-01-18 17:02:06        -73.974670   \n",
              "2562 2015-01-08 23:03:43  2015-01-08 23:34:35        -73.983040   \n",
              "2563 2015-01-04 15:57:16  2015-01-04 16:01:35        -73.985565   \n",
              "\n",
              "      dropoff_longitude  pickup_latitude  dropoff_latitude    tip  \\\n",
              "0            -73.965454        40.756008         40.766533   1.55   \n",
              "1            -73.789909        40.743591         40.646961   8.00   \n",
              "2            -73.971748        40.770859         40.765907   1.00   \n",
              "3            -73.952293        40.762680         40.769730   3.12   \n",
              "4            -73.982346        40.726257         40.756344   2.85   \n",
              "...                 ...              ...               ...    ...   \n",
              "2559         -73.981346        40.767986         40.767494   1.00   \n",
              "2560         -73.978668        40.733135         40.744980   0.00   \n",
              "2561         -73.981972        40.756886         40.765900   1.00   \n",
              "2562         -73.879776        40.767727         40.701225  10.40   \n",
              "2563         -73.978149        40.747116         40.752449   1.15   \n",
              "\n",
              "      total_amount  coordinate_distance  dayofweek  year  month  day  hour  \n",
              "0             9.35             1.184941          6  2015      1    4    11  \n",
              "1            66.13            19.576706          6  2015      1   11     5  \n",
              "2            13.30             2.088758          3  2015      1   15    14  \n",
              "3            16.42             3.238871          4  2015      1    9    23  \n",
              "4            17.15             3.361178          1  2015      1   13    20  \n",
              "...            ...                  ...        ...   ...    ...  ...   ...  \n",
              "2559          5.80             0.077765          5  2015      1    3    20  \n",
              "2560         13.30             2.460882          5  2015      1   24    23  \n",
              "2561         10.80             1.175928          6  2015      1   18    16  \n",
              "2562         52.03            11.418538          3  2015      1    8    23  \n",
              "2563          6.95             0.861324          6  2015      1    4    15  \n",
              "\n",
              "[2564 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f775978-a245-408c-b929-b4ac1e293e27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>tip</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>coordinate_distance</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-04 11:45:30</td>\n",
              "      <td>2015-01-04 11:53:14</td>\n",
              "      <td>-73.967659</td>\n",
              "      <td>-73.965454</td>\n",
              "      <td>40.756008</td>\n",
              "      <td>40.766533</td>\n",
              "      <td>1.55</td>\n",
              "      <td>9.35</td>\n",
              "      <td>1.184941</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-11 05:40:34</td>\n",
              "      <td>2015-01-11 06:04:40</td>\n",
              "      <td>-73.984016</td>\n",
              "      <td>-73.789909</td>\n",
              "      <td>40.743591</td>\n",
              "      <td>40.646961</td>\n",
              "      <td>8.00</td>\n",
              "      <td>66.13</td>\n",
              "      <td>19.576706</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-15 14:53:55</td>\n",
              "      <td>2015-01-15 15:09:55</td>\n",
              "      <td>-73.947823</td>\n",
              "      <td>-73.971748</td>\n",
              "      <td>40.770859</td>\n",
              "      <td>40.765907</td>\n",
              "      <td>1.00</td>\n",
              "      <td>13.30</td>\n",
              "      <td>2.088758</td>\n",
              "      <td>3</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-09 23:37:38</td>\n",
              "      <td>2015-01-09 23:51:00</td>\n",
              "      <td>-73.989609</td>\n",
              "      <td>-73.952293</td>\n",
              "      <td>40.762680</td>\n",
              "      <td>40.769730</td>\n",
              "      <td>3.12</td>\n",
              "      <td>16.42</td>\n",
              "      <td>3.238871</td>\n",
              "      <td>4</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-13 20:16:03</td>\n",
              "      <td>2015-01-13 20:32:07</td>\n",
              "      <td>-73.986198</td>\n",
              "      <td>-73.982346</td>\n",
              "      <td>40.726257</td>\n",
              "      <td>40.756344</td>\n",
              "      <td>2.85</td>\n",
              "      <td>17.15</td>\n",
              "      <td>3.361178</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2559</th>\n",
              "      <td>2015-01-03 20:35:33</td>\n",
              "      <td>2015-01-03 20:37:43</td>\n",
              "      <td>-73.982002</td>\n",
              "      <td>-73.981346</td>\n",
              "      <td>40.767986</td>\n",
              "      <td>40.767494</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5.80</td>\n",
              "      <td>0.077765</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2560</th>\n",
              "      <td>2015-01-24 23:57:18</td>\n",
              "      <td>2015-01-25 00:13:38</td>\n",
              "      <td>-74.003342</td>\n",
              "      <td>-73.978668</td>\n",
              "      <td>40.733135</td>\n",
              "      <td>40.744980</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.30</td>\n",
              "      <td>2.460882</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2561</th>\n",
              "      <td>2015-01-18 16:49:45</td>\n",
              "      <td>2015-01-18 17:02:06</td>\n",
              "      <td>-73.974670</td>\n",
              "      <td>-73.981972</td>\n",
              "      <td>40.756886</td>\n",
              "      <td>40.765900</td>\n",
              "      <td>1.00</td>\n",
              "      <td>10.80</td>\n",
              "      <td>1.175928</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2562</th>\n",
              "      <td>2015-01-08 23:03:43</td>\n",
              "      <td>2015-01-08 23:34:35</td>\n",
              "      <td>-73.983040</td>\n",
              "      <td>-73.879776</td>\n",
              "      <td>40.767727</td>\n",
              "      <td>40.701225</td>\n",
              "      <td>10.40</td>\n",
              "      <td>52.03</td>\n",
              "      <td>11.418538</td>\n",
              "      <td>3</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2563</th>\n",
              "      <td>2015-01-04 15:57:16</td>\n",
              "      <td>2015-01-04 16:01:35</td>\n",
              "      <td>-73.985565</td>\n",
              "      <td>-73.978149</td>\n",
              "      <td>40.747116</td>\n",
              "      <td>40.752449</td>\n",
              "      <td>1.15</td>\n",
              "      <td>6.95</td>\n",
              "      <td>0.861324</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2564 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f775978-a245-408c-b929-b4ac1e293e27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f775978-a245-408c-b929-b4ac1e293e27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f775978-a245-408c-b929-b4ac1e293e27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094b4d6d",
      "metadata": {
        "id": "094b4d6d"
      },
      "source": [
        "### Processing Uber Data\n",
        "\n",
        "_Write some prose that tells the reader what you're about to do here._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c58e3a2",
      "metadata": {
        "id": "7c58e3a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "e2d7e8cf-8678-4223-dfb6-d0fcd8e89ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34931\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       fare_amount           pickup_datetime  pickup_longitude  \\\n",
              "0             7.50 2015-05-07 19:52:06+00:00        -73.999817   \n",
              "1             7.70 2009-07-17 20:04:56+00:00        -73.994355   \n",
              "2            12.90 2009-08-24 21:45:00+00:00        -74.005043   \n",
              "3             5.30 2009-06-26 08:22:21+00:00        -73.976124   \n",
              "4            16.00 2014-08-28 17:47:00+00:00        -73.925023   \n",
              "...            ...                       ...               ...   \n",
              "34926         7.00 2013-07-22 22:58:00+00:00        -73.971210   \n",
              "34927         4.10 2009-03-17 16:40:34+00:00        -73.989167   \n",
              "34928         6.00 2014-06-12 20:03:00+00:00        -73.976287   \n",
              "34929        20.83 2013-04-09 10:21:38+00:00        -73.988428   \n",
              "34930        16.50 2011-04-03 12:44:31+00:00        -74.001600   \n",
              "\n",
              "       pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
              "0            40.738354         -73.999512         40.723217   \n",
              "1            40.728225         -73.994710         40.750325   \n",
              "2            40.740770         -73.962565         40.772647   \n",
              "3            40.790844         -73.965316         40.803349   \n",
              "4            40.744085         -73.973082         40.761247   \n",
              "...                ...                ...               ...   \n",
              "34926        40.751287         -73.977215         40.752325   \n",
              "34927        40.762935         -73.991962         40.754702   \n",
              "34928        40.760280         -73.983277         40.763827   \n",
              "34929        40.670634         -74.013862         40.714818   \n",
              "34930        40.727635         -73.983275         40.781579   \n",
              "\n",
              "       coordinate_distance  dayofweek  year  month  day  hour  \n",
              "0                 1.683323          3  2015      5    7    19  \n",
              "1                 2.457590          4  2009      7   17    20  \n",
              "2                 5.036377          0  2009      8   24    21  \n",
              "3                 1.661683          4  2009      6   26     8  \n",
              "4                 4.475450          3  2014      8   28    17  \n",
              "...                    ...        ...   ...    ...  ...   ...  \n",
              "34926             0.518833          0  2013      7   22    22  \n",
              "34927             0.945251          1  2009      3   17    16  \n",
              "34928             0.708619          3  2014      6   12    20  \n",
              "34929             5.360608          1  2013      4    9    10  \n",
              "34930             6.193716          6  2011      4    3    12  \n",
              "\n",
              "[34931 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-298fb412-84e8-4127-84eb-a5721e8b2a31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>coordinate_distance</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.50</td>\n",
              "      <td>2015-05-07 19:52:06+00:00</td>\n",
              "      <td>-73.999817</td>\n",
              "      <td>40.738354</td>\n",
              "      <td>-73.999512</td>\n",
              "      <td>40.723217</td>\n",
              "      <td>1.683323</td>\n",
              "      <td>3</td>\n",
              "      <td>2015</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.70</td>\n",
              "      <td>2009-07-17 20:04:56+00:00</td>\n",
              "      <td>-73.994355</td>\n",
              "      <td>40.728225</td>\n",
              "      <td>-73.994710</td>\n",
              "      <td>40.750325</td>\n",
              "      <td>2.457590</td>\n",
              "      <td>4</td>\n",
              "      <td>2009</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.90</td>\n",
              "      <td>2009-08-24 21:45:00+00:00</td>\n",
              "      <td>-74.005043</td>\n",
              "      <td>40.740770</td>\n",
              "      <td>-73.962565</td>\n",
              "      <td>40.772647</td>\n",
              "      <td>5.036377</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>8</td>\n",
              "      <td>24</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.30</td>\n",
              "      <td>2009-06-26 08:22:21+00:00</td>\n",
              "      <td>-73.976124</td>\n",
              "      <td>40.790844</td>\n",
              "      <td>-73.965316</td>\n",
              "      <td>40.803349</td>\n",
              "      <td>1.661683</td>\n",
              "      <td>4</td>\n",
              "      <td>2009</td>\n",
              "      <td>6</td>\n",
              "      <td>26</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16.00</td>\n",
              "      <td>2014-08-28 17:47:00+00:00</td>\n",
              "      <td>-73.925023</td>\n",
              "      <td>40.744085</td>\n",
              "      <td>-73.973082</td>\n",
              "      <td>40.761247</td>\n",
              "      <td>4.475450</td>\n",
              "      <td>3</td>\n",
              "      <td>2014</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34926</th>\n",
              "      <td>7.00</td>\n",
              "      <td>2013-07-22 22:58:00+00:00</td>\n",
              "      <td>-73.971210</td>\n",
              "      <td>40.751287</td>\n",
              "      <td>-73.977215</td>\n",
              "      <td>40.752325</td>\n",
              "      <td>0.518833</td>\n",
              "      <td>0</td>\n",
              "      <td>2013</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34927</th>\n",
              "      <td>4.10</td>\n",
              "      <td>2009-03-17 16:40:34+00:00</td>\n",
              "      <td>-73.989167</td>\n",
              "      <td>40.762935</td>\n",
              "      <td>-73.991962</td>\n",
              "      <td>40.754702</td>\n",
              "      <td>0.945251</td>\n",
              "      <td>1</td>\n",
              "      <td>2009</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34928</th>\n",
              "      <td>6.00</td>\n",
              "      <td>2014-06-12 20:03:00+00:00</td>\n",
              "      <td>-73.976287</td>\n",
              "      <td>40.760280</td>\n",
              "      <td>-73.983277</td>\n",
              "      <td>40.763827</td>\n",
              "      <td>0.708619</td>\n",
              "      <td>3</td>\n",
              "      <td>2014</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34929</th>\n",
              "      <td>20.83</td>\n",
              "      <td>2013-04-09 10:21:38+00:00</td>\n",
              "      <td>-73.988428</td>\n",
              "      <td>40.670634</td>\n",
              "      <td>-74.013862</td>\n",
              "      <td>40.714818</td>\n",
              "      <td>5.360608</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34930</th>\n",
              "      <td>16.50</td>\n",
              "      <td>2011-04-03 12:44:31+00:00</td>\n",
              "      <td>-74.001600</td>\n",
              "      <td>40.727635</td>\n",
              "      <td>-73.983275</td>\n",
              "      <td>40.781579</td>\n",
              "      <td>6.193716</td>\n",
              "      <td>6</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34931 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-298fb412-84e8-4127-84eb-a5721e8b2a31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-298fb412-84e8-4127-84eb-a5721e8b2a31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-298fb412-84e8-4127-84eb-a5721e8b2a31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "def load_and_clean_uber_data(csv_file):\n",
        "  df = pd.read_csv(csv_file)\n",
        "  df=df.drop(columns=['Unnamed: 0','key','passenger_count'])\n",
        "  df = df.dropna(how='any')\n",
        "  df = df.loc[df.pickup_longitude.between(-74.242330,-73.717047) & df.dropoff_longitude.between(-74.242330,-73.717047) \n",
        "    & df.pickup_latitude.between(40.560445,40.908524)& df.dropoff_latitude.between(40.560445,40.908524)]\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  return df\n",
        "\n",
        "def get_uber_data():\n",
        "  uber_dataframe = load_and_clean_uber_data(UBER_CSV)\n",
        "  df=add_distance_column(uber_dataframe)\n",
        "  df[\"pickup_datetime\"] = pd.to_datetime(df['pickup_datetime'])\n",
        "  df[\"dayofweek\"] = df[\"pickup_datetime\"].dt.dayofweek\n",
        "  df[\"year\"] = df[\"pickup_datetime\"].dt.year\n",
        "  df[\"month\"] = df[\"pickup_datetime\"].dt.month\n",
        "  df[\"day\"] = df[\"pickup_datetime\"].dt.day\n",
        "  df[\"hour\"] = df[\"pickup_datetime\"].dt.hour\n",
        "  return df\n",
        "uber=get_uber_data()\n",
        "uber"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a15cbb",
      "metadata": {
        "id": "45a15cbb"
      },
      "source": [
        "### Processing Weather Data\n",
        "\n",
        "_Write some prose that tells the reader what you're about to do here._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e864ab",
      "metadata": {
        "id": "76e864ab"
      },
      "outputs": [],
      "source": [
        "def clean_month_weather_data_hourly(csv_file):\n",
        "    we = pd.read_csv(csv_file)\n",
        "    f1 = ['DATE', 'HourlyPrecipitation', 'HourlyWindSpeed']\n",
        "    we_1 = pd.DataFrame()\n",
        "    for i in f1:\n",
        "        col1=we.loc[:,we.columns.str.contains(i)]\n",
        "        we_1=pd.concat([we_1, col1], axis=1)\n",
        "    hourly_clean= we_1.dropna()\n",
        "    hourly_clean.reset_index(drop=True, inplace=True)\n",
        "    hourly_clean[\"DATE\"] = pd.to_datetime(hourly_clean['DATE'])\n",
        "    hourly_clean[\"YEAR\"] = hourly_clean[\"DATE\"].dt.year\n",
        "    hourly_clean[\"MONTH\"] = hourly_clean[\"DATE\"].dt.month\n",
        "    hourly_clean[\"DAY\"] = hourly_clean[\"DATE\"].dt.day\n",
        "    hourly_clean[\"HOUR\"] = hourly_clean[\"DATE\"].dt.hour\n",
        "    return hourly_clean\n",
        "\n",
        "def clean_month_weather_data_daily(csv_file):\n",
        "    we = pd.read_csv(csv_file)\n",
        "    f2 = ['DATE', 'DailySustainedWindSpeed']\n",
        "    we_2 = pd.DataFrame()\n",
        "    for i in f2:\n",
        "        col2=we.loc[:,we.columns.str.contains(i)]\n",
        "        we_2=pd.concat([we_2, col2], axis=1)\n",
        "    daily_clean= we_2.dropna()\n",
        "    daily_clean.reset_index(drop=True, inplace=True)\n",
        "    daily_clean[\"DATE\"] = pd.to_datetime(daily_clean['DATE'])\n",
        "    daily_clean[\"YEAR\"] = daily_clean[\"DATE\"].dt.year\n",
        "    daily_clean[\"MONTH\"] = daily_clean[\"DATE\"].dt.month\n",
        "    daily_clean[\"DAY\"] = daily_clean[\"DATE\"].dt.day\n",
        "    daily_clean[\"HOUR\"] = daily_clean[\"DATE\"].dt.hour\n",
        "    return daily_clean\n",
        "    \n",
        "\n",
        "def load_and_clean_weather_data():\n",
        "    hourly_dataframes = []\n",
        "    daily_dataframes = []\n",
        "    \n",
        "    # add some way to find all weather CSV files\n",
        "    # or just add the name/paths manually\n",
        "    weather_csv_files = [\"2009_weather.csv\", \n",
        "                         \"2010_weather.csv\", \n",
        "                         \"2011_weather.csv\",\n",
        "                         \"2012_weather.csv\",\n",
        "                         \"2013_weather.csv\",\n",
        "                         \"2014_weather.csv\",\n",
        "                         \"2015_weather.csv\"]\n",
        "    \n",
        "    for csv_file in weather_csv_files:\n",
        "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
        "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
        "        hourly_dataframes.append(hourly_dataframe)\n",
        "        daily_dataframes.append(daily_dataframe)\n",
        "        \n",
        "    # create two dataframes with hourly & daily data from every month\n",
        "    hourly_data = pd.concat(hourly_dataframes)\n",
        "    daily_data = pd.concat(daily_dataframes)\n",
        "    return hourly_data, daily_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_and_clean_weather_data() "
      ],
      "metadata": {
        "id": "fkHtnwt3FnKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f148de45-09ab-42a5-b54f-84f129e52cba"
      },
      "id": "fkHtnwt3FnKW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DtypeWarning: Columns (8,9,10,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (8,9,10,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DtypeWarning: Columns (17,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (17,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DtypeWarning: Columns (8,9,17,18,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (8,9,17,18,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DtypeWarning: Columns (10,41,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (10,41,78) have mixed types.Specify dtype option on import or set low_memory=False.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                     DATE HourlyPrecipitation  HourlyWindSpeed\n",
              " 0     2009-01-02T12:34:00                   T             14.0\n",
              " 1     2009-01-02T12:51:00                   T             11.0\n",
              " 2     2009-01-02T13:05:00                   T              7.0\n",
              " 3     2009-01-02T13:30:00                   T              9.0\n",
              " 4     2009-01-02T13:46:00                   T             10.0\n",
              " ...                   ...                 ...              ...\n",
              " 9102  2015-12-31T18:51:00                0.00              3.0\n",
              " 9103  2015-12-31T19:51:00                0.00              6.0\n",
              " 9104  2015-12-31T20:51:00                0.00             10.0\n",
              " 9105  2015-12-31T22:51:00                0.00              7.0\n",
              " 9106  2015-12-31T23:51:00                0.00              5.0\n",
              " \n",
              " [38260 rows x 3 columns],                     DATE  DailySustainedWindSpeed\n",
              " 0    2012-07-31T23:59:00                     10.0\n",
              " 1    2012-08-01T23:59:00                      9.0\n",
              " 2    2012-08-02T23:59:00                     12.0\n",
              " 3    2012-08-03T23:59:00                      9.0\n",
              " 4    2012-08-04T23:59:00                     12.0\n",
              " ..                   ...                      ...\n",
              " 360  2015-12-27T23:59:00                     15.0\n",
              " 361  2015-12-28T23:59:00                     18.0\n",
              " 362  2015-12-29T23:59:00                     18.0\n",
              " 363  2015-12-30T23:59:00                      9.0\n",
              " 364  2015-12-31T23:59:00                     14.0\n",
              " \n",
              " [1249 rows x 2 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('/content/drive/MyDrive/taxi_data_clean/', '20*.csv'))), ignore_index= True)\n",
        "df.drop(columns = ['Unnamed: 0'])\n",
        "df.to_csv('taxi_data_clean.csv')\n",
        "#df['tip'].isna().sum()"
      ],
      "metadata": {
        "id": "aGskM0SwXR1B"
      },
      "id": "aGskM0SwXR1B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f900f7aa",
      "metadata": {
        "id": "f900f7aa"
      },
      "source": [
        "### Process All Data\n",
        "\n",
        "_This is where you can actually execute all the required functions._\n",
        "\n",
        "_Write some prose that tells the reader what you're about to do here._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7cd53a6",
      "metadata": {
        "id": "f7cd53a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30c6305-109e-4cfe-d8fc-1f760bcfb0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "195472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DtypeWarning: Columns (8,9,10,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DtypeWarning: Columns (8,9,10,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DtypeWarning: Columns (17,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DtypeWarning: Columns (17,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DtypeWarning: Columns (8,9,17,18,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DtypeWarning: Columns (8,9,17,18,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DtypeWarning: Columns (10,41,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DtypeWarning: Columns (10,41,78) have mixed types.Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ],
      "source": [
        "taxi_data = pd.read_csv('taxi_data_clean.csv')\n",
        "uber_data = get_uber_data()\n",
        "hourly_weather, daily_weather = load_and_clean_weather_data()\n",
        "all_trips = pd.concat([taxi_data, uber_data], axis=0, ignore_index=True)\n",
        "all_trips=all_trips.drop(columns=['dropoff_datetime','tip','total_amount','fare_amount'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[\"pickup_datetime\"] = pd.to_datetime(a[\"pickup_datetime\"])\n",
        "a[\"dayofweek\"] = a[\"pickup_datetime\"].dt.dayofweek\n",
        "a[\"year\"] = a[\"pickup_datetime\"].dt.year\n",
        "a[\"month\"] = a[\"pickup_datetime\"].dt.month\n",
        "a[\"day\"] = a[\"pickup_datetime\"].dt.day\n",
        "a[\"hour\"] = a[\"pickup_datetime\"].dt.hour\n",
        "a=a.drop(columns=['distance'])\n",
        "a"
      ],
      "metadata": {
        "id": "Isak6-OEh9YV"
      },
      "id": "Isak6-OEh9YV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dd101f11",
      "metadata": {
        "id": "dd101f11"
      },
      "source": [
        "## Part 2: Storing Cleaned Data\n",
        "\n",
        "_Write some prose that tells the reader what you're about to do here._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3529cf6",
      "metadata": {
        "id": "f3529cf6"
      },
      "outputs": [],
      "source": [
        "engine = db.create_engine(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2bea0ff",
      "metadata": {
        "id": "d2bea0ff"
      },
      "outputs": [],
      "source": [
        "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
        "# to create your 4 tables/dataframes\n",
        "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS hourly_weather\n",
        "(\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    DATE TEXT,\n",
        "    HourlyPrecipitation FLOAT,\n",
        "    HourlyWindSpeed FLOAT,\n",
        "    YEAR INTEGER,\n",
        "    MONTH INTEGER,\n",
        "    DAY INTEGER,\n",
        "    HOUR INTEGER\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "DAILY_WEATHER_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS daily_weather\n",
        "(\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    DATE TEXT,\n",
        "    DailySustainedWindSpeed FLOAT,\n",
        "    YEAR INTEGER,\n",
        "    MONTH INTEGER,\n",
        "    DAY INTEGER,\n",
        "    HOUR INTEGER\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "TAXI_TRIPS_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS taxi_trips\n",
        "(\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    pickup_datetime DATETIME,\n",
        "    dropoff_datetime DATETIME,\n",
        "    pickup_longitude FLOAT,\n",
        "    dropoff_longitude FLOAT,\n",
        "    pickup_latitude FLOAT,\n",
        "    dropoff_latitude FLOAT,\n",
        "    tip FLOAT,\n",
        "    total_amount FLOAT,\n",
        "    coordinate_distance FLOAT,\n",
        "    dayofweek INTEGER,\n",
        "    year INTEGER,\n",
        "    month INTEGER,\n",
        "    day INTEGER,\n",
        "    hour INTEGER\n",
        "\n",
        "\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "UBER_TRIPS_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS uber_trips\n",
        "(\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    fare_amount FLOAT,\n",
        "    pickup_datetime DATETIME,\n",
        "    pickup_longitude FLOAT,\n",
        "    pickup_latitude FLOAT,\n",
        "    dropoff_longitude\tFLOAT,\n",
        "    dropoff_latitude FLOAT,\n",
        "    coordinate_distance FLOAT,\n",
        "    dayofweek INTEGER,\n",
        "    year INTEGER,\n",
        "    month INTEGER,\n",
        "    day INTEGER,\n",
        "    hour INTEGER\n",
        "\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "ALL_TRIPS_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS all_trips\n",
        "(\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    pickup_datetime DATETIME,\n",
        "    pickup_longitude FLOAT,\n",
        "    dropoff_longitude FLOAT,\n",
        "    pickup_latitude FLOAT,\n",
        "    dropoff_latitude FLOAT,\n",
        "    coordinate_distance FLOAT,\n",
        "    dayofweek INTEGER,\n",
        "    year INTEGER,\n",
        "    month INTEGER,\n",
        "    day INTEGER,\n",
        "    hour INTEGER\n",
        "\n",
        ")\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f41e54b",
      "metadata": {
        "id": "5f41e54b"
      },
      "outputs": [],
      "source": [
        "# create that required schema.sql file\n",
        "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
        "    f.write(HOURLY_WEATHER_SCHEMA)\n",
        "    f.write(DAILY_WEATHER_SCHEMA)\n",
        "    f.write(TAXI_TRIPS_SCHEMA)\n",
        "    f.write(UBER_TRIPS_SCHEMA)\n",
        "    f.write(ALL_TRIPS_SCHEMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02eccdba",
      "metadata": {
        "id": "02eccdba"
      },
      "outputs": [],
      "source": [
        "# create the tables with the schema files\n",
        "with engine.connect() as connection:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c122964f",
      "metadata": {
        "id": "c122964f"
      },
      "source": [
        "### Add Data to Database\n",
        "\n",
        "_Write some prose that tells the reader what you're about to do here._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e68a363",
      "metadata": {
        "id": "0e68a363"
      },
      "outputs": [],
      "source": [
        "def dataframes_to_table(table_name_to_dataframe):\n",
        "  for key in table_name_to_dataframe:\n",
        "    table_name_to_dataframe[key].to_sql(key, con=engine, if_exists=\"replace\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d6c06c",
      "metadata": {
        "id": "45d6c06c"
      },
      "outputs": [],
      "source": [
        "table_name_to_dataframe = {\n",
        "    \"taxi_trips\": taxi_data,\n",
        "    \"uber_trips\": uber_data,\n",
        "    \"hourly_weather\": hourly_weather,\n",
        "    \"daily_weather\": daily_weather,\n",
        "    \"all_trips\":all_trips\n",
        "}\n",
        "\n",
        "dataframes_to_table(table_name_to_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#engine.execute(\"SELECT * FROM daily_weather\").fetchall()"
      ],
      "metadata": {
        "id": "YDQEQMvhJOdf"
      },
      "id": "YDQEQMvhJOdf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8cb6e33e",
      "metadata": {
        "id": "8cb6e33e"
      },
      "source": [
        "## Part 3: Understanding the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4753fcd",
      "metadata": {
        "id": "b4753fcd"
      },
      "source": [
        "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
        "\n",
        "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
        "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
        "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
        "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
        "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
        "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "engine.execute(\"SELECT hour AS Hour, COUNT(*) AS Trips FROM taxi_trips GROUP BY Hour ORDER BY Trips DESC\").fetchall()\n"
      ],
      "metadata": {
        "id": "xZ5mg2aLOeRD"
      },
      "id": "xZ5mg2aLOeRD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "q2 = engine.execute(\"SELECT dayofweek AS Weekday, COUNT(*) AS Trips FROM uber_trips GROUP BY dayofweek ORDER BY Trips DESC\").fetchall()\n",
        "write_query_to_file(q2, 1)"
      ],
      "metadata": {
        "id": "7C1P4O0fSE_6"
      },
      "id": "7C1P4O0fSE_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "query = \"\"\"\n",
        "SELECT coordinate_distance AS '95% percentile of distance'\n",
        "FROM all_trips\n",
        "WHERE year = 2013 AND month = 7\n",
        "ORDER BY coordinate_distance ASC\n",
        "LIMIT 1\n",
        "OFFSET (\n",
        "SELECT CAST(COUNT(coordinate_distance)*0.95-1 AS INT) FROM all_trips WHERE year = 2013 AND month = 7)\n",
        "\"\"\"\n",
        "engine.execute(query).fetchall()"
      ],
      "metadata": {
        "id": "NOcLn8O0rgqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76121182-300e-45c8-dd78-1a8dd0800636"
      },
      "id": "NOcLn8O0rgqw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10.231468318625527,)]"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ef04df",
      "metadata": {
        "id": "a2ef04df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e814f4cf-8283-416a-a1ce-aea7da121bee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12, 11, 127, 2.97589203472042),\n",
              " (10, 23, 123, 2.4524671315098834),\n",
              " (8, 14, 119, 3.548617620635577),\n",
              " (4, 18, 113, 3.329794125272145),\n",
              " (1, 31, 112, 2.7919509511955884),\n",
              " (5, 8, 111, 3.3112073580725196),\n",
              " (7, 9, 111, 3.4544163807019315),\n",
              " (3, 19, 110, 3.294181937318452),\n",
              " (5, 16, 109, 2.7727537127507222),\n",
              " (4, 4, 108, 2.6060268703851786)]"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "#Q4\n",
        "query = \"\"\"\n",
        "SELECT month, day, COUNT(*) AS trips, AVG(coordinate_distance) as average_distance\n",
        "FROM all_trips\n",
        "WHERE year = 2009\n",
        "GROUP BY month, day\n",
        "ORDER BY trips DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "engine.execute(query).fetchall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "query = \"\"\"\n",
        "SELECT mix.month, mix.day, DailySustainedWindSpeed as WindSpeed, COUNT(*) as trips\n",
        "FROM daily_weather mix\n",
        "JOIN all_trips daily_weather\n",
        "ON mix.month = daily_weather.month AND mix.day = daily_weather.day AND mix.year = daily_weather.YEAR \n",
        "WHERE mix.year = 2014\n",
        "GROUP BY mix.month, mix.day\n",
        "ORDER BY DailySustainedWindSpeed DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "engine.execute(query).fetchall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk_xi8885gSk",
        "outputId": "d21cef3f-259b-481b-9688-78b1ce9c2e6a"
      },
      "id": "mk_xi8885gSk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 13, 25.0, 63),\n",
              " (12, 7, 25.0, 73),\n",
              " (1, 7, 23.0, 77),\n",
              " (3, 13, 23.0, 106),\n",
              " (3, 26, 23.0, 96),\n",
              " (3, 29, 23.0, 107),\n",
              " (1, 22, 22.0, 61),\n",
              " (2, 14, 22.0, 71),\n",
              " (11, 18, 22.0, 86),\n",
              " (12, 9, 22.0, 70)]"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6\n",
        "query = \"\"\"\n",
        "SELECT re.month, re.day, re.hour, HourlyPrecipitation, HourlyWindSpeed, COUNT(*) as trips\n",
        "FROM hourly_weather re\n",
        "JOIN all_trips hourly_weather\n",
        "ON re.year = hourly_weather.year AND re.month = hourly_weather.month AND re.day = hourly_weather.day AND re.hour = hourly_weather.hour\n",
        "WHERE re.year = 2012 AND ((re.month = 10 AND re.day >= 22) OR (re.month = 11 AND re.day <= 6))\n",
        "GROUP BY re.month, re.day, re.hour\n",
        "\"\"\"\n",
        "engine.execute(query).fetchall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggG1hvZ3-NDn",
        "outputId": "15e2c131-c9a1-4bd7-8146-8f325da980d1"
      },
      "id": "ggG1hvZ3-NDn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10, 22, 0, '0.00', 7.0, 2),\n",
              " (10, 22, 2, '0.00', 7.0, 1),\n",
              " (10, 22, 3, '0.00', 0.0, 1),\n",
              " (10, 22, 5, '0.00', 0.0, 1),\n",
              " (10, 22, 6, '0.00', 5.0, 3),\n",
              " (10, 22, 7, '0.00', 3.0, 5),\n",
              " (10, 22, 8, '0.00', 3.0, 1),\n",
              " (10, 22, 9, '0.00', 5.0, 5),\n",
              " (10, 22, 12, '0.00', 11.0, 5),\n",
              " (10, 22, 14, '0.00', 7.0, 1),\n",
              " (10, 22, 15, '0.00', 6.0, 1),\n",
              " (10, 22, 16, '0.00', 3.0, 6),\n",
              " (10, 22, 17, '0.00', 7.0, 4),\n",
              " (10, 22, 18, '0.00', 5.0, 8),\n",
              " (10, 22, 19, '0.00', 5.0, 2),\n",
              " (10, 22, 20, '0.00', 3.0, 4),\n",
              " (10, 22, 21, '0.00', 0.0, 1),\n",
              " (10, 22, 22, '0.00', 3.0, 6),\n",
              " (10, 23, 12, 'T', 0.0, 1),\n",
              " (10, 23, 19, 'T', 0.0, 2),\n",
              " (10, 23, 20, '0.02', 0.0, 8),\n",
              " (10, 23, 21, 'T', 5.0, 4),\n",
              " (10, 23, 22, '0.01', 0.0, 6),\n",
              " (10, 23, 23, 'T', 5.0, 3),\n",
              " (10, 24, 2, '0.00', 5.0, 4),\n",
              " (10, 24, 5, '0.00', 6.0, 2),\n",
              " (10, 24, 7, 'T', 0.0, 1),\n",
              " (10, 24, 8, 'T', 0.0, 2),\n",
              " (10, 24, 9, 'T', 3.0, 4),\n",
              " (10, 24, 10, '0.00', 7.0, 2),\n",
              " (10, 24, 11, '0.00', 7.0, 4),\n",
              " (10, 24, 12, 'T', 7.0, 6),\n",
              " (10, 24, 13, '0.00', 8.0, 4),\n",
              " (10, 24, 14, '0.00', 7.0, 2),\n",
              " (10, 24, 15, '0.00', 7.0, 4),\n",
              " (10, 24, 16, '0.00', 8.0, 2),\n",
              " (10, 24, 17, '0.00', 5.0, 5),\n",
              " (10, 24, 18, '0.00', 7.0, 4),\n",
              " (10, 24, 19, '0.00', 8.0, 5),\n",
              " (10, 24, 20, '0.00', 3.0, 7),\n",
              " (10, 24, 21, '0.00', 5.0, 7),\n",
              " (10, 24, 22, '0.00', 6.0, 5),\n",
              " (10, 24, 23, '0.00', 0.0, 3),\n",
              " (10, 25, 0, '0.00', 3.0, 5),\n",
              " (10, 25, 1, '0.00', 3.0, 1),\n",
              " (10, 25, 2, '0.00', 3.0, 2),\n",
              " (10, 25, 4, '0.00', 6.0, 1),\n",
              " (10, 25, 5, '0.00', 0.0, 2),\n",
              " (10, 25, 6, '0.00', 5.0, 4),\n",
              " (10, 25, 7, '0.00', 6.0, 3),\n",
              " (10, 25, 8, '0.00', 5.0, 6),\n",
              " (10, 25, 9, '0.00', 3.0, 2),\n",
              " (10, 25, 10, '0.00', 6.0, 4),\n",
              " (10, 25, 11, '0.00', 0.0, 5),\n",
              " (10, 25, 12, '0.00', 6.0, 7),\n",
              " (10, 25, 13, '0.00', 0.0, 3),\n",
              " (10, 25, 14, '0.00', 5.0, 3),\n",
              " (10, 25, 15, '0.00', 5.0, 5),\n",
              " (10, 25, 16, '0.00', 0.0, 1),\n",
              " (10, 25, 17, '0.00', 3.0, 4),\n",
              " (10, 25, 18, '0.00', 0.0, 4),\n",
              " (10, 25, 19, '0.00', 0.0, 1),\n",
              " (10, 25, 20, '0.00', 3.0, 13),\n",
              " (10, 25, 21, '0.00', 3.0, 8),\n",
              " (10, 25, 22, '0.00', 3.0, 6),\n",
              " (10, 25, 23, '0.00', 0.0, 3),\n",
              " (10, 26, 0, '0.00', 5.0, 2),\n",
              " (10, 26, 1, '0.00', 0.0, 1),\n",
              " (10, 26, 2, '0.00', 0.0, 3),\n",
              " (10, 26, 3, '0.00', 3.0, 2),\n",
              " (10, 26, 4, '0.00', 0.0, 2),\n",
              " (10, 26, 5, '0.00', 0.0, 1),\n",
              " (10, 26, 7, '0.00', 3.0, 4),\n",
              " (10, 26, 9, '0.00', 3.0, 7),\n",
              " (10, 26, 10, '0.00', 3.0, 3),\n",
              " (10, 26, 11, '0.00', 3.0, 4),\n",
              " (10, 26, 12, '0.00', 0.0, 2),\n",
              " (10, 26, 13, '0.00', 3.0, 7),\n",
              " (10, 26, 14, '0.00', 3.0, 5),\n",
              " (10, 26, 15, '0.00', 0.0, 3),\n",
              " (10, 26, 16, '0.00', 0.0, 2),\n",
              " (10, 26, 17, '0.00', 0.0, 3),\n",
              " (10, 26, 18, '0.00', 0.0, 3),\n",
              " (10, 26, 19, '0.00', 0.0, 5),\n",
              " (10, 26, 20, '0.00', 3.0, 10),\n",
              " (10, 26, 21, '0.00', 3.0, 4),\n",
              " (10, 26, 22, '0.00', 0.0, 8),\n",
              " (10, 26, 23, '0.00', 0.0, 4),\n",
              " (10, 27, 0, '0.00', 3.0, 6),\n",
              " (10, 27, 1, '0.00', 0.0, 3),\n",
              " (10, 27, 2, '0.00', 3.0, 6),\n",
              " (10, 27, 3, '0.00', 0.0, 4),\n",
              " (10, 27, 5, '0.00', 6.0, 2),\n",
              " (10, 27, 6, '0.00', 6.0, 1),\n",
              " (10, 27, 7, '0.00', 3.0, 1),\n",
              " (10, 27, 9, '0.00', 6.0, 6),\n",
              " (10, 27, 10, '0.00', 9.0, 2),\n",
              " (10, 27, 11, '0.00', 6.0, 1),\n",
              " (10, 27, 12, '0.00', 8.0, 5),\n",
              " (10, 27, 13, '0.00', 8.0, 2),\n",
              " (10, 27, 14, '0.00', 10.0, 3),\n",
              " (10, 27, 15, '0.00', 10.0, 3),\n",
              " (10, 27, 16, '0.00', 7.0, 8),\n",
              " (10, 27, 17, '0.00', 7.0, 10),\n",
              " (10, 27, 18, '0.00', 7.0, 7),\n",
              " (10, 27, 19, '0.00', 9.0, 6),\n",
              " (10, 27, 20, '0.00', 7.0, 9),\n",
              " (10, 27, 21, '0.00', 9.0, 6),\n",
              " (10, 27, 22, '0.00', 9.0, 7),\n",
              " (10, 27, 23, '0.00', 8.0, 8),\n",
              " (10, 28, 0, '0.00', 11.0, 6),\n",
              " (10, 28, 1, '0.00', 8.0, 8),\n",
              " (10, 28, 2, '0.00', 8.0, 3),\n",
              " (10, 28, 3, '0.00', 9.0, 3),\n",
              " (10, 28, 4, '0.00', 10.0, 4),\n",
              " (10, 28, 5, '0.00', 11.0, 1),\n",
              " (10, 28, 7, '0.00', 11.0, 2),\n",
              " (10, 28, 8, '0.00', 11.0, 1),\n",
              " (10, 28, 9, '0.00', 11.0, 4),\n",
              " (10, 28, 10, '0.00', 10.0, 2),\n",
              " (10, 28, 11, '0.00', 8.0, 5),\n",
              " (10, 28, 12, '0.00', 7.0, 2),\n",
              " (10, 28, 13, '0.00', 13.0, 3),\n",
              " (10, 28, 14, '0.00', 13.0, 5),\n",
              " (10, 28, 15, '0.00', 13.0, 6),\n",
              " (10, 28, 16, '0.00', 16.0, 4),\n",
              " (10, 28, 17, '0.00', 11.0, 4),\n",
              " (10, 28, 18, '0.00', 15.0, 5),\n",
              " (10, 28, 19, '0.00', 14.0, 3),\n",
              " (10, 28, 20, '0.00', 16.0, 4),\n",
              " (10, 28, 21, '0.00', 14.0, 3),\n",
              " (10, 28, 22, '0.00', 16.0, 3),\n",
              " (10, 28, 23, '0.00', 14.0, 1),\n",
              " (10, 29, 0, '0.00', 16.0, 1),\n",
              " (10, 29, 2, '0.00', 13.0, 1),\n",
              " (10, 29, 4, '0.00', 15.0, 1),\n",
              " (10, 29, 7, '0.02', 17.0, 1),\n",
              " (10, 29, 9, '0.00', 16.0, 1),\n",
              " (10, 29, 11, 'T', 17.0, 9),\n",
              " (10, 29, 12, '0.06', 20.0, 20),\n",
              " (10, 29, 14, '0.02', 24.0, 6),\n",
              " (10, 29, 15, '0.11', 24.0, 4),\n",
              " (10, 29, 17, '0.07', 25.0, 4),\n",
              " (10, 29, 18, '0.02', 25.0, 6),\n",
              " (10, 29, 21, '0.00', 15.0, 1),\n",
              " (10, 30, 0, '0.02', 10.0, 2),\n",
              " (10, 30, 4, 'T', 9.0, 1),\n",
              " (10, 30, 9, '0.09', 10.0, 6),\n",
              " (10, 30, 10, '0.03', 6.0, 9),\n",
              " (10, 30, 11, '0.00', 7.0, 3),\n",
              " (10, 30, 12, '0.00', 7.0, 2),\n",
              " (10, 30, 13, '0.00', 6.0, 3),\n",
              " (10, 30, 16, '0.01', 6.0, 3),\n",
              " (10, 30, 17, '0.00', 5.0, 3),\n",
              " (10, 30, 18, '0.00', 5.0, 2),\n",
              " (10, 30, 19, '0.00', 3.0, 4),\n",
              " (10, 30, 20, '0.00', 7.0, 2),\n",
              " (10, 30, 21, '0.00', 5.0, 2),\n",
              " (10, 30, 22, '0.00', 7.0, 3),\n",
              " (10, 30, 23, '0.00', 9.0, 2),\n",
              " (10, 31, 2, 'T', 0.0, 3),\n",
              " (10, 31, 6, '0.00', 6.0, 2),\n",
              " (10, 31, 7, '0.00', 8.0, 3),\n",
              " (10, 31, 8, '0.00', 7.0, 1),\n",
              " (10, 31, 9, '0.00', 8.0, 2),\n",
              " (10, 31, 10, '0.00', 3.0, 2),\n",
              " (10, 31, 11, '0.00', 5.0, 3),\n",
              " (10, 31, 13, '0.00', 6.0, 2),\n",
              " (10, 31, 14, '0.00', 5.0, 3),\n",
              " (10, 31, 15, '0.00', 3.0, 2),\n",
              " (10, 31, 16, '0.00', 5.0, 2),\n",
              " (10, 31, 18, '0.00', 3.0, 6),\n",
              " (10, 31, 19, '0.00', 9.0, 3),\n",
              " (10, 31, 20, '0.00', 7.0, 1),\n",
              " (10, 31, 21, '0.00', 7.0, 1),\n",
              " (10, 31, 22, '0.00', 6.0, 4),\n",
              " (10, 31, 23, '0.00', 3.0, 1),\n",
              " (11, 1, 0, '0.00', 3.0, 2),\n",
              " (11, 1, 4, '0.00', 7.0, 1),\n",
              " (11, 1, 6, '0.00', 13.0, 1),\n",
              " (11, 1, 8, '0.00', 7.0, 2),\n",
              " (11, 1, 9, '0.00', 3.0, 2),\n",
              " (11, 1, 10, '0.00', 6.0, 5),\n",
              " (11, 1, 11, '0.00', 6.0, 5),\n",
              " (11, 1, 12, '0.00', 11.0, 5),\n",
              " (11, 1, 13, '0.00', 8.0, 2),\n",
              " (11, 1, 14, '0.00', 8.0, 2),\n",
              " (11, 1, 16, '0.00', 5.0, 2),\n",
              " (11, 1, 17, '0.00', 5.0, 2),\n",
              " (11, 1, 18, '0.00', 9.0, 6),\n",
              " (11, 1, 19, '0.00', 3.0, 6),\n",
              " (11, 1, 20, '0.00', 5.0, 4),\n",
              " (11, 1, 21, '0.00', 8.0, 1),\n",
              " (11, 1, 22, '0.00', 5.0, 4),\n",
              " (11, 1, 23, '0.00', 0.0, 1),\n",
              " (11, 2, 0, '0.00', 5.0, 3),\n",
              " (11, 2, 3, '0.00', 3.0, 1),\n",
              " (11, 2, 5, '0.00', 5.0, 1),\n",
              " (11, 2, 8, '0.00', 5.0, 3),\n",
              " (11, 2, 10, '0.00', 9.0, 2),\n",
              " (11, 2, 11, '0.00', 7.0, 3),\n",
              " (11, 2, 12, '0.00', 7.0, 3),\n",
              " (11, 2, 13, '0.00', 6.0, 1),\n",
              " (11, 2, 14, '0.00', 6.0, 4),\n",
              " (11, 2, 15, '0.00', 5.0, 4),\n",
              " (11, 2, 16, '0.00', 11.0, 3),\n",
              " (11, 2, 17, '0.00', 8.0, 1),\n",
              " (11, 2, 18, '0.00', 9.0, 1),\n",
              " (11, 2, 19, '0.00', 7.0, 4),\n",
              " (11, 2, 20, '0.00', 9.0, 5),\n",
              " (11, 2, 21, '0.00', 7.0, 6),\n",
              " (11, 2, 22, '0.00', 8.0, 5),\n",
              " (11, 2, 23, '0.00', 8.0, 3),\n",
              " (11, 3, 0, '0.00', 7.0, 7),\n",
              " (11, 3, 1, '0.00', 7.0, 1),\n",
              " (11, 3, 2, '0.00', 7.0, 6),\n",
              " (11, 3, 5, '0.00', 8.0, 1),\n",
              " (11, 3, 6, '0.00', 7.0, 1),\n",
              " (11, 3, 7, '0.00', 6.0, 1),\n",
              " (11, 3, 8, '0.00', 10.0, 1),\n",
              " (11, 3, 9, '0.00', 13.0, 3),\n",
              " (11, 3, 10, '0.00', 6.0, 2),\n",
              " (11, 3, 11, '0.00', 13.0, 8),\n",
              " (11, 3, 12, '0.00', 13.0, 3),\n",
              " (11, 3, 13, '0.00', 8.0, 2),\n",
              " (11, 3, 14, '0.00', 8.0, 6),\n",
              " (11, 3, 15, '0.00', 7.0, 3),\n",
              " (11, 3, 16, '0.00', 10.0, 2),\n",
              " (11, 3, 17, '0.00', 9.0, 8),\n",
              " (11, 3, 18, '0.00', 9.0, 6),\n",
              " (11, 3, 19, '0.00', 13.0, 4),\n",
              " (11, 3, 20, '0.00', 10.0, 4),\n",
              " (11, 3, 21, '0.00', 9.0, 8),\n",
              " (11, 3, 22, '0.00', 0.0, 5),\n",
              " (11, 3, 23, '0.00', 7.0, 9),\n",
              " (11, 4, 0, '0.00', 9.0, 6),\n",
              " (11, 4, 1, '0.00', 7.0, 10),\n",
              " (11, 4, 2, '0.00', 7.0, 7),\n",
              " (11, 4, 3, '0.00', 7.0, 1),\n",
              " (11, 4, 4, '0.00', 8.0, 3),\n",
              " (11, 4, 5, '0.00', 6.0, 1),\n",
              " (11, 4, 7, '0.00', 3.0, 1),\n",
              " (11, 4, 8, '0.00', 7.0, 2),\n",
              " (11, 4, 9, '0.00', 9.0, 1),\n",
              " (11, 4, 11, '0.00', 6.0, 5),\n",
              " (11, 4, 12, '0.00', 8.0, 7),\n",
              " (11, 4, 13, '0.00', 8.0, 4),\n",
              " (11, 4, 14, '0.00', 7.0, 3),\n",
              " (11, 4, 15, '0.00', 7.0, 2),\n",
              " (11, 4, 16, '0.00', 5.0, 4),\n",
              " (11, 4, 17, '0.00', 5.0, 6),\n",
              " (11, 4, 19, '0.00', 7.0, 5),\n",
              " (11, 4, 21, '0.00', 7.0, 2),\n",
              " (11, 4, 22, '0.00', 6.0, 3),\n",
              " (11, 4, 23, '0.00', 5.0, 1),\n",
              " (11, 5, 0, '0.00', 0.0, 1),\n",
              " (11, 5, 1, '0.00', 5.0, 1),\n",
              " (11, 5, 5, '0.00', 6.0, 1),\n",
              " (11, 5, 6, '0.00', 8.0, 3),\n",
              " (11, 5, 7, '0.00', 6.0, 3),\n",
              " (11, 5, 8, '0.00', 7.0, 4),\n",
              " (11, 5, 9, '0.00', 3.0, 6),\n",
              " (11, 5, 10, '0.00', 3.0, 4),\n",
              " (11, 5, 11, '0.00', 3.0, 3),\n",
              " (11, 5, 12, '0.00', 5.0, 3),\n",
              " (11, 5, 13, '0.00', 3.0, 4),\n",
              " (11, 5, 15, '0.00', 8.0, 2),\n",
              " (11, 5, 17, '0.00', 5.0, 15),\n",
              " (11, 5, 18, '0.00', 5.0, 7),\n",
              " (11, 5, 19, '0.00', 0.0, 4),\n",
              " (11, 5, 20, '0.00', 3.0, 7),\n",
              " (11, 5, 21, '0.00', 7.0, 5),\n",
              " (11, 5, 22, '0.00', 6.0, 2),\n",
              " (11, 5, 23, '0.00', 9.0, 1),\n",
              " (11, 6, 0, '0.00', 6.0, 4),\n",
              " (11, 6, 1, '0.00', 5.0, 1),\n",
              " (11, 6, 2, '0.00', 8.0, 2),\n",
              " (11, 6, 3, '0.00', 10.0, 1),\n",
              " (11, 6, 4, '0.00', 6.0, 1),\n",
              " (11, 6, 5, '0.00', 5.0, 2),\n",
              " (11, 6, 6, '0.00', 7.0, 1),\n",
              " (11, 6, 7, '0.00', 7.0, 4),\n",
              " (11, 6, 8, '0.00', 8.0, 4),\n",
              " (11, 6, 9, '0.00', 3.0, 3),\n",
              " (11, 6, 10, '0.00', 6.0, 4),\n",
              " (11, 6, 11, '0.00', 7.0, 1),\n",
              " (11, 6, 12, '0.00', 5.0, 5),\n",
              " (11, 6, 13, '0.00', 0.0, 7),\n",
              " (11, 6, 14, '0.00', 6.0, 7),\n",
              " (11, 6, 15, '0.00', 6.0, 4),\n",
              " (11, 6, 16, '0.00', 5.0, 4),\n",
              " (11, 6, 17, '0.00', 5.0, 6),\n",
              " (11, 6, 18, '0.00', 3.0, 5),\n",
              " (11, 6, 19, '0.00', 3.0, 9),\n",
              " (11, 6, 20, '0.00', 7.0, 3),\n",
              " (11, 6, 21, '0.00', 7.0, 2),\n",
              " (11, 6, 22, '0.00', 7.0, 4),\n",
              " (11, 6, 23, '0.00', 3.0, 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a13ced42",
      "metadata": {
        "id": "a13ced42"
      },
      "source": [
        "## Part 4: Visualizing the Data\n",
        "\n",
        "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
        "\n",
        "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
        "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
        "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
        "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
        "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
        "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
        "* [ ] Come up with 3 questions on your own that can be answered based on the data in the 4 tables. Create at least one visualization to answer each question. At least one visualization should require data from at least 3 tables.\n",
        "\n",
        "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d9eef42",
      "metadata": {
        "id": "6d9eef42"
      },
      "source": [
        "### Visualization N\n",
        "\n",
        "_Write some prose that tells the reader what you're about to do here._\n",
        "\n",
        "_Repeat for each visualization._\n",
        "\n",
        "_You don't have to query the data directly from the database. You can just re-use the pandas DataFrame that you created in Part 1._\n",
        "\n",
        "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de8394c",
      "metadata": {
        "id": "0de8394c"
      },
      "outputs": [],
      "source": [
        "# use a more descriptive name for your function\n",
        "def plot_visual_n(dataframe):\n",
        "    figure, axes = plt.subplots(figsize=(20, 10))\n",
        "    \n",
        "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
        "    \n",
        "    # you may want to use matplotlib to plot your visualizations;\n",
        "    # there are also many other plot types (other \n",
        "    # than axes.plot) you can use\n",
        "    axes.plot(values, \"...\")\n",
        "    # there are other methods to use to label your axes, to style \n",
        "    # and set up axes labels, etc\n",
        "    axes.set_title(\"Some Descriptive Title\")\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c63e845",
      "metadata": {
        "id": "3c63e845"
      },
      "outputs": [],
      "source": [
        "plot_visual_n(some_dataframe)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}